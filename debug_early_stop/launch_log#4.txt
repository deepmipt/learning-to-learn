2018-06-07 23:03:05.188571

launch regime: train

build parameters:
{
    "num_output_nodes": [],
    "optimizer": "sgd",
    "num_output_layers": 1,
    "init_parameter": 3.0,
    "num_nodes": [
        100],
    "embedding_size": 150,
    "num_unrollings": 10,
    "vocabulary_size": 27,
    "num_gpus": 1,
    "going_to_limit_memory": True,
    "num_layers": 1,
    "batch_size": 32,
    "additional_metrics": [
        "bpc",
        "perplexity",
        "accuracy"]}

launch parameters:
{
    "kwargs": {
        "learning_rate": {
            "type": "adaptive_change",
            "init_value": 4.0,
            "path_to_target_metric_storage": (
                "default_1",
                "loss"),
            "max_no_progress_points": 10,
            "decay": 0.5},
        "additions_to_feed_dict": [
            {
                "placeholder": "dropout",
                "value": 0.9}],
        "results_collect_interval": 100,
        "allow_growth": True,
        "validation_additions_to_feed_dict": [
            {
                "placeholder": "dropout",
                "value": 1.0}],
        "no_validation": False,
        "printed_result_types": [
            "perplexity",
            "loss",
            "bpc",
            "accuracy"],
        "train_dataset_text": VERY_LONG_STRING,
        "batch_size": 32,
        "vocabulary": [
            " ",
            "a",
            "b",
            "c",
            "d",
            "e",
            "f",
            "g",
            "h",
            "i",
            "j",
            "k",
            "l",
            "m",
            "n",
            "o",
            "p",
            "q",
            "r",
            "s",
            "t",
            "u",
            "v",
            "w",
            "x",
            "y",
            "z"],
        "result_types": [
            "perplexity",
            "loss",
            "bpc",
            "accuracy"],
        "num_unrollings": 10,
        "stop": 4000,
        "validation_dataset_texts": [
            VERY_LONG_STRING],
        "checkpoint_steps": None,
        "save_path": "debug_early_stop"},
    "args": (,),
    "close_session": True,
    "set_passed_parameters_as_default": False,
    "start_session": True}

default launch parameters:
{
    "session_specs": {
        "allow_soft_placement": False,
        "allow_growth": False,
        "log_device_placement": False,
        "gpu_memory": None,
        "visible_device_list": ""},
    "run": {
        "schedule": {
            "to_be_collected_while_training": {
                "example_per_print": 1,
                "print_per_collected": 1,
                "results_collect_interval": 100},
            "example_length": None,
            "printed_result_types": [
                "loss"],
            "example_tensors": {
                "example_save_tensors": {},
                "example_print_tensors": {}},
            "fuses": None,
            "replicas": None,
            "validation_tensor_schedule": {
                "valid_print_tensors": {},
                "valid_save_text_tensors": {}},
            "random": {
                "number_of_runs": 5,
                "length": 80},
            "train_tensor_schedule": {
                "train_print_text_tensors": {},
                "train_summary_tensors": {},
                "train_save_tensors": {},
                "train_print_tensors": {},
                "train_save_text_tensors": {}},
            "printed_controllers": [
                "learning_rate"],
            "fuse_tensors": {
                "fuse_print_tensors": {},
                "fuse_save_tensors": {}}},
        "train_specs": {
            "debug": None,
            "learning_rate": {
                "type": "exponential_decay",
                "name": "learning_rate",
                "init": 0.002,
                "period": 1000,
                "decay": 0.8},
            "additions_to_feed_dict": [],
            "no_validation": False,
            "batch_size": {
                "type": "fixed",
                "value": 64,
                "name": "batch_size"},
            "train_dataset": None,
            "validation_batch_size": 1,
            "valid_batch_kwargs": {},
            "validation_additions_to_feed_dict": [],
            "validate_tokens_by_chars": False,
            "validation_datasets": None,
            "train_batch_kwargs": {},
            "checkpoint_steps": None,
            "stop": {
                "type": "limit_steps",
                "limit": 10000,
                "name": "stop"}}},
    "start_specs": {
        "vocabulary": [
            " ",
            "a",
            "b",
            "c",
            "d",
            "e",
            "f",
            "g",
            "h",
            "i",
            "j",
            "k",
            "l",
            "m",
            "n",
            "o",
            "p",
            "q",
            "r",
            "s",
            "t",
            "u",
            "v",
            "w",
            "x",
            "y",
            "z"],
        "result_types": [
            "loss",
            "perplexity",
            "accuracy"],
        "restore_path": None,
        "meta_optimizer_restore_path": None,
        "add_graph_to_summary": False,
        "batch_generator_class": <class 'learning_to_learn.lstm_for_meta.LstmFastBatchGenerator'>,
        "summary": False,
        "with_meta_optimizer": False,
        "save_path": None}}

